{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Adversarial Example Generation- (FGSM) .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmP1EwMDlDnGlGg3f8NCM7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akintoyeai/FGSM/blob/main/Adversarial_Example_Generation_(FGSM)_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoS9hXnD3nLo"
      },
      "outputs": [],
      "source": [
        "# The FGSM attack is a white-box attack with the aim of misclassification"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# to get around \"User-agent\" limitations when downloading MNIST datasets\n",
        "from six.moves import urllib\n",
        "opener = urllib.request.build_opener()\n",
        "opener.addheaders = [(\"User-agent\", \"Mozila/5.0\")]\n",
        "urllib.request.install_opener(opener)\n"
      ],
      "metadata": {
        "id": "vgeJlJE85U12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inputs\n",
        "epsilons = [0, .05, .1, .15, .2, .25, .3]\n",
        "pretrained_model = \"lenet_mnist_model.pth\"\n",
        "# GPU isnt critical to run the model, but is used in this case \n",
        "use_cuda = True "
      ],
      "metadata": {
        "id": "DqoGBGJz8qFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "    \n",
        "    def forward(self,x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)),2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim =1)\n",
        "\n",
        "# Dataset and dataloader declaration\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\"../data\", train=False, download = True, transform = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            ])),\n",
        "        batch_size = 1, shuffle = True\n",
        "    )\n",
        "\n",
        "# Define what device we are using\n",
        "print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n",
        "\n",
        "# Initialize the network\n",
        "model = Net().to(device)\n",
        "\n",
        "# Load the pretrained model\n",
        "model.load_state_dict(torch.load(pretrained_model, map_location='cpu'))\n",
        "\n",
        "# Set the model in evaluation mode. In this case this is for the Dropout layers\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrYUjx8N_J5V",
        "outputId": "48ca8ef9-ef0a-4bde-d14a-e1f43a9a4793"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Available:  False\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Conv2d(1, 10, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
              "  (conv2_drop): Dropout2d(p=0.5, inplace=False)\n",
              "  (fc1): Linear(in_features=320, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# FGSM Attack code\n",
        "\n",
        "def fgsm_attack(image, epsilon, data_grad):\n",
        "    # Collect the element-wise sign of the data gradient\n",
        "    sign_data_grad = data_grad.sign()\n",
        "    # Create the perturbed image by adjusting each pixel of the input image\n",
        "    perturbed_image = image + epsilon*sign_data_grad\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
        "\n",
        "    return perturbed_image"
      ],
      "metadata": {
        "id": "Nh7reCOmKUB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test( model, device, test_loader, epsilon ):\n",
        "\n",
        "    # Accuracy counter\n",
        "    correct = 0\n",
        "    adv_examples = []\n",
        "\n",
        "    # Loop over all examples in test set\n",
        "    for data, target in test_loader:\n",
        "\n",
        "        # Send the data and label to the device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Set requires_grad attribute of tensor. Important for Attack\n",
        "        data.requires_grad = True\n",
        "\n",
        "        # Forward pass the data through the model\n",
        "        output = model(data)\n",
        "        init_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "\n",
        "        # If the initial prediction is wrong, dont bother attacking, just move on\n",
        "        if init_pred.item() != target.item():\n",
        "            continue\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = F.nll_loss(output, target)\n",
        "\n",
        "        # Zero all existing gradients\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Calculate gradients of model in backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Collect datagrad\n",
        "        data_grad = data.grad.data\n",
        "\n",
        "        # Call FGSM Attack\n",
        "        perturbed_data = fgsm_attack(data, epsilon, data_grad)\n",
        "\n",
        "        # Re-classify the perturbed image\n",
        "        output = model(perturbed_data)\n",
        "\n",
        "        # Check for success\n",
        "        final_pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
        "        if final_pred.item() == target.item():\n",
        "            correct += 1\n",
        "            # Special case for saving 0 epsilon examples\n",
        "            if (epsilon == 0) and (len(adv_examples) < 5):\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "        else:\n",
        "            # Save some adv examples for visualization later\n",
        "            if len(adv_examples) < 5:\n",
        "                adv_ex = perturbed_data.squeeze().detach().cpu().numpy()\n",
        "                adv_examples.append( (init_pred.item(), final_pred.item(), adv_ex) )\n",
        "\n",
        "    # Calculate final accuracy for this epsilon\n",
        "    final_acc = correct/float(len(test_loader))\n",
        "    print(\"Epsilon: {}\\tTest Accuracy = {} / {} = {}\".format(epsilon, correct, len(test_loader), final_acc))\n",
        "\n",
        "    # Return the accuracy and an adversarial example\n",
        "    return final_acc, adv_examples"
      ],
      "metadata": {
        "id": "OMcGKGpsNc-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracies = []\n",
        "examples = []\n",
        "\n",
        "# Run test for each epsilon\n",
        "for eps in epsilons:\n",
        "    acc, ex = test(model, device, test_loader, eps)\n",
        "    accuracies.append(acc)\n",
        "    examples.append(ex)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEzasV4_Nfxa",
        "outputId": "9fd03bd3-a774-4978-c7ad-f3d6b077cd9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epsilon: 0\tTest Accuracy = 9810 / 10000 = 0.981\n",
            "Epsilon: 0.05\tTest Accuracy = 9426 / 10000 = 0.9426\n",
            "Epsilon: 0.1\tTest Accuracy = 8510 / 10000 = 0.851\n",
            "Epsilon: 0.15\tTest Accuracy = 6826 / 10000 = 0.6826\n",
            "Epsilon: 0.2\tTest Accuracy = 4301 / 10000 = 0.4301\n",
            "Epsilon: 0.25\tTest Accuracy = 2082 / 10000 = 0.2082\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(5,5))\n",
        "plt.plot(epsilons, accuracies, \"*-\")\n",
        "plt.yticks(np.arange(0, 1.1, step=0.1))\n",
        "plt.xticks(np.arange(0, .35, step=0.05))\n",
        "plt.title(\"Accuracy vs Epsilon\")\n",
        "plt.xlabel(\"Epsilon\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6qJedmFMNjnE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot several examples of adversarial samples at each epsilon\n",
        "cnt = 0\n",
        "plt.figure(figsize=(8,10))\n",
        "for i in range(len(epsilons)):\n",
        "    for j in range(len(examples[i])):\n",
        "        cnt += 1\n",
        "        plt.subplot(len(epsilons),len(examples[0]),cnt)\n",
        "        plt.xticks([], [])\n",
        "        plt.yticks([], [])\n",
        "        if j == 0:\n",
        "            plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
        "        orig,adv,ex = examples[i][j]\n",
        "        plt.title(\"{} -> {}\".format(orig, adv))\n",
        "        plt.imshow(ex, cmap=\"gray\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zp9qgHGcNlIu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}